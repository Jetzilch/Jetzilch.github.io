<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[粗糙度研究现状]]></title>
    <url>%2F2019%2F04%2F06%2F%E7%B2%97%E7%B3%99%E5%BA%A6%E7%A0%94%E7%A9%B6%E7%8E%B0%E7%8A%B6%2F</url>
    <content type="text"><![CDATA[一、起源Patton（1966）用模型试验证实了规则突起岩体符合某个强度准则。 由于实际结构面大多数凹凸不平，起伏角变化较大，而且研究表明Patton起伏角在不同正应力下力学效应不同，于是 Barton提出了新的不规则岩体结构面抗剪强度经验公式，公式中JRC的量测比较困难和复杂。 二、现有确定JRC的方法 Barton标准剖面法 优点：ISRM采用，简单省时不用计算 缺点：精度不高误差大，近年已很少使用 直接测量法（结构面起伏角可通过比较七剖面的全迹长和直线迹长得到） 优点：较Barton法精度有所提高 缺点：真实的全迹长确定较为困难，即使是同一剖面每次量测结果亦均不相同。选择剖面较多，工作量大，并要动用复杂仪器。 表面粗糙参数法 优点：量测过程精度高 缺点：对仪器要求严格，工作量大，若非自动连续记录仪器量测则可导致较大误差，使精度下降。 伸长率法 优点：精度较高 缺点：物理意义不明确，精度和可靠性还有待理论上论证和时间经验积累 幅度法 优点：简单省时 缺点：仅考虑结构面最大起伏幅度是相对结构面长度而言的，没有考虑较小突起体对JRC的贡献，因此精度变化较大。 分形维数法 优点：有良好的理论基础和较高的精度，目前较为完善的方法之一。 三、粗糙度分形维数法进展早期由于设备限制，主要集中于 3.1 节理轮廓线的分形描述，主要获取方法有 针状轮廓尺法，简易纵剖面仪法，RSP-I型智能岩石表面形貌仪法，接触打孔器法，阴影轮廓线法。 近年来，随着设备推陈出新，结构面三维形貌数据较容易获得，主要获取设备有 3D型便携式岩石三位表面形貌仪，三维激光扫描岩石表面仪。 3.2 结构面的分形描述3.2.1 间接描述采用节理轮廓线分维数加1或计算结构面上一条或多条节理轮廓线的自仿射分形的Hurst指数H，然后根据D=3-H获得结构面分形维数。3.2.2 直接量测三角形棱柱表面积法投影覆盖法立方体覆盖法 四、结构面的多重分形描述五、粗糙度表征方案备选石林-3D岩体结构面粗糙度表征方法优点：1.测量便捷，能快速获取现场结构面的形态特征，且计算出的粗糙度具有精确度和可靠度；2.是一种3D角度的评价方法，更全面地考虑结构面的特征，综合反映结构面形态；3.能够反映结构面粗糙度的各向异性、尺寸效应和间距效应这三个影响因素。4.没有复杂的计算过程，具有操作简单便于推广的优点。缺点：尚未建立面积拓展率S和结构面起伏度Rs与岩体结构面抗剪强度的关系。 方法的由来：伸长率：1.伸长率法既考虑了节理相对长度，也考虑了节理剖面起伏变化的因素，而幅度法只考虑了最大的起伏幅度，没有考虑较小的起伏幅度对抗剪强度的影响。2.用伸长率确定节理粗糙度系数的精度主要取决于测量仪器的精度（现在有三维激光扫描仪能保证精度） 直边法和修正直边法：1.岩体结构面表面形态具有各质异性、各向异性和非均一性，定向统计测量方法是保证JRC测量精度的基本方法。2.直边法具有明确的物理意义，有精度保证、测速快、操作简便等优点。修正直边法是Barton直边法的扩充，具有比直边法更强的普适性。3.修正直边法的数学表达式包容了JRC的尺寸效应规律，配合计算机使用，适用于岩体结构面JRC的统计测量。#各质异性：成因、类型和规模相同的同一组结构面，由于所处岩石性质不同，结构面的表面形态和JRC存在明显差异。各向异性：成因、类型和规模相同的同一组结构面，即使处于同一岩石中，结构面的表面形态和粗糙度系数JRC也会因为岩石介质的各向异性，结构面形成时应力环境的各项异性而呈现各项异性。非均一性：处于同一岩石中的同一组结构面，即使沿同一方向进行量测时，各测量段的表面形态和粗糙度系数JRC也存在差异。 上述方法的缺点：伸长率法虽全面考虑了结构面剖面轮廓曲线的结构特征，但是没有区分大小起伏度在影响抗剪效果时的主次权重；而直边法（修正直边法）仅考虑了大的结构起伏对结构面抗剪强度的影响，忽略了小结构起伏对抗剪强度的影响作用。因此，单独使用这2种方法不能确保JRC取值的精确度和可靠度. 李化等将伸长率R和轮廓曲线的相对起伏度Ra两个指标结合起来，让2种方法得到互补，提出了更精确的计算方法. 该方法不仅考虑了结构面大的结构起伏对结构面抗剪强度的影响，同时也考虑了较小结构起伏对抗剪强度的影响，并区分了两者的影响权重，具有较高的精确性和可靠性。 对某一确定的结构面来说，面积扩展率S是一个定值，该参数可以反映结构面粗糙度的尺寸效应和间距效应，但不能反映各向异性。而相对起伏度Ra则可以很好地反映出各向异性，在沿不同剪切方向上具有不同的剖面轮廓曲线，因此该参数可以作为体现结构面粗糙度具有各向异性的指标。从描述结构面粗糙度的特征上来说，相对起伏度Ra弥补了面积扩展率S的不足，这2个参数结合描述结构面的粗糙程度具有可行性.]]></content>
      <categories>
        <category>技能</category>
      </categories>
      <tags>
        <tag>粗糙度</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[会议拍摄技巧]]></title>
    <url>%2F2019%2F04%2F04%2F%E4%BC%9A%E8%AE%AE%E6%8B%8D%E6%91%84%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[一、空场景 会议现场大场景：光线明亮，场内无闲杂人等，干净整洁。场景带有会议主题和LOGO 局部场景：签到带礼仪（显得准备充分） 二、会议流程拍摄 舞台大景：左中右三个角度拍摄，需要一张包括所有领导的主席台照片/外加领导发言的特写/再拍一张台下参与者的大场景 观众大景：高角度俯视拍摄观众全景，微俯视角度将每个代表座位拍出来 三、特写 演讲嘉宾45°特写，正面特写以及带LOGO进入画面，拍摄嘉宾要突出，主体占三分之二，虚化占三分之一 观众中景：认真聆听领导讲话，鼓掌点头 合影：顺光]]></content>
      <categories>
        <category>技能</category>
      </categories>
      <tags>
        <tag>摄影</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019聚餐]]></title>
    <url>%2F2019%2F04%2F03%2F2019%E8%81%9A%E9%A4%90%2F</url>
    <content type="text"><![CDATA[0131 去姐夫家和姐夫吃夜宵喝酒 0217 去李锡鹏家吃饭 0219 阿冰哥和姐夫请我吃赣湘楼 0219 和妈妈吃烤海鲜 0222 XP、罗新食尚 0224 返校6人聚餐（鸡公煲） 0226 9人新食尚聚餐 0304 勇哥来我这做菜（腊肠）不要再喝牛栏山了 0309 去华科大西路吃烧烤，肉串的味道比小堕好点。 0320 北阶一家还不错的菜馆，有卖烤鱼，喝了啤酒，感觉并不好喝。 0322 学工组聚餐，口味堂，有点贵啊，今天主要吃的菜，口味鱼头200+接近300，菠菜面，红豆紫薯汁、牛蛙（平锅小美蛙）、饼（包紫薯还是什么来着）、口味粉蒸排骨、三峡石烤馍、虾仁水蒸蛋（因为没有公勺，所以我尽量挖边边的部分）千层扣肉（挺好吃的，一点都不辣，感觉不像是湖南菜啊，听老师们的说话好像这是湖南菜的餐厅） 0325 罗带腊肉来我这做，外加XP、勇哥的四个人小聚（感谢罗带的肉，碗还是罗洗的，优秀） 0325 中午和博、XP在教育食堂吃的，千张肉丝，香焖土鸡，干煸四季豆，家常豆腐都挺好吃的，天予推荐的，不错不错 0331 和孙技星一起吃老街烧烤。 0401 南门天天烧烤（XP请的） 0402 教育食堂（博请的，天予） 0403 教育食堂（我请的，XP）]]></content>
      <categories>
        <category>自律即自由</category>
      </categories>
      <tags>
        <tag>聚餐</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019年4月考核]]></title>
    <url>%2F2019%2F04%2F03%2F2019%E5%B9%B44%E6%9C%88%E8%80%83%E6%A0%B8%2F</url>
    <content type="text"><![CDATA[第一周（0401-0407）0401 周一 科研 晚上看了粗糙度的文献，没什么收获 读博 今天做了写高数题 环境 其它 0402 周二 科研 读博 莫烦Python基础完成；莫烦Numpy和Pandas开始 环境 其它 爱，死亡与机器人看完，只留下喜欢的几集，zima blue挺有共鸣。 0403 周三 科研 读博 莫烦python看到numpy的基本运算2 环境 其它 《快速使用Hexo搭建个人博客》学到11集（markdown基本语法）；看完crash course:study skills并在Hexo做了笔记。 0404 周四 科研 读博 莫烦python看到numpy的合并 环境 参加张国旗清明纪念仪式；张老师指导拍摄技巧 其它 Hexo搭建博客学习完毕； 0405 周五 科研 读博 莫烦numpy和Pandas数据处理完毕 环境 其它 0406 周六 科研 大致了解粗糙度研究现状，并做了一定整理，发布在博客上 读博 环境 其它 开始学素描，卡在色阶和正方体的明暗上，估计是笔的原因]]></content>
      <categories>
        <category>自律即自由</category>
      </categories>
      <tags>
        <tag>2019</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[B站Hexo博客搭建的个人博客]]></title>
    <url>%2F2019%2F04%2F03%2FB%E7%AB%99Hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E7%9A%84%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[一、主题安装Git安装然后更改_config.yml中的theme。 二、主题语言修改更改_config.yml中language(zh-CN) 三、增加标签页和分类页next主题文件夹中的_config.yml（与上述不是同一个文件）中搜索menu，找到#categories、#tags，去掉前面的#号，保存，更新。 四、正确打开标签页和分类页12$ hexo n page tags //创建标签页$ hexo n page categories //创建分类页 五、主题样式更改next文件夹中_config.yml中搜索scheme,增删#进行更改 六、更改头像next文件夹中_config.yml中搜索avatar中url:/images/avatar.gif，改成想要的图片(图片要提前存入相应的文件夹) 七、更改标题、作者以及链接在_config.yml中搜索author，对title、author、url进行修改。 八、启用侧边栏社交链接next中的_config.yml搜索social进行修改 九、启用友情链接next中的_config.yml搜索links，找到links： Title:…进行更改 十、新建一篇文章tags: - 标签名1 - 标签名2 categories: 分类名 十一、Markdown基本语法见博客中《markdown基本语法》 十二、开启打赏功能next–_fonfig.yml–搜”reward” 十三、开启订阅公众号next–_config.yml–搜”sub” 十四、设置头像为圆形可旋转视频 十五、首页文章设置阅读全文next–_config.yml–搜“auto”/&lt; !– more – &gt; 十六、添加动态背景next–_config.yml–搜”Canvas” 十七、给博客添加fork Github百度“Github corners”找到喜欢的复制，然后在next/layout/_layout.swig中的1&lt;dir class=&quot;headband&quot;&gt;&lt;/dir&gt;dir&gt; 后另起一行，粘贴，并修改1&lt;a = href=&quot;...&quot;&gt; // &quot;...&quot;为你的github网址 十九、修改文章底部带#的标签next/layout/_macro/post.swig找到….rel = “tags”&gt; # … #改成1&lt;i class = &quot;...&quot; &gt;&lt;/i&gt; 二十、增加搜索功能next/_config.yml 二十三、增加搜索功能官方文档–第三方服务–搜索–local search 二十四、增加不蒜子统计功能next/_config.yml搜“busuanzi” 二十五、增加分享内容（没找到对应内容）二十八、隐藏底部的强力驱动next/layout/_partias/footer.swig 三十、hexo博客部署到远端的githubgithub先创建仓库 – git init（博客文件夹）– npm install hexo-deployer-git – –save – hexo d PS:部分视频没有看，有需要再去看。]]></content>
      <categories>
        <category>技能</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown基本语法]]></title>
    <url>%2F2019%2F04%2F03%2Fmarkdown%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[一级标题二级标题三级标题四级标题五级标题六级标题 列表1 列表2 子列表2.1 子列表2.2 列表3 Jetzilch的Github 斜线字体字体加粗 单行代码块 12多行代码块1多行代码块2 这部分内容是引用的，主要以原作者的内容为主。 加一条横线（视频演示的是虚的，但是这里显示的就是实的了。。。）加一条横虚线]]></content>
      <categories>
        <category>技能</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Crash Course:Study Skills]]></title>
    <url>%2F2019%2F04%2F03%2FCrash-Course-Study-Skills%2F</url>
    <content type="text"><![CDATA[一、笔记载体和笔记方法的选择1.1 笔记载体：Paper√/Computer原因：Paper虽然记录速度慢，但不容易分心，且能提供更多的思考空间。1.2 笔记方法：大纲法/康奈尔法/思维导图 根据实际情况选择1.3 如何记笔记：如何划重点? 摩斯电码法（觉得是重点在段落旁边画·，之后有对这个重点解释证明阐述的，在段落旁边画-） 二、阅读方法（1）现有的研究证明速读是不可能的，或者说是没有效果的。（2）不要抑制默读，抑制默读影响思考。（3）阅读顺序：浏览-问题-阅读-复述/做题/总结（4）最好的阅读法：SCAR（Stop Complaining And Reading） 三、记忆（1）记忆需要间隔。（2）适度难度原则：回忆起越难想起的记忆，记忆的效果越好，但是如果刻意延长回忆时间可能造成无法回忆起记忆而导致记忆丢失。可以使用莱特纳系统进行复习，即找到5个盒子，分别为隔1，3，5，7，考试前五个时间，学习的知识依照时间长短放入各个盒子，然后根据盒子的天数进行复习。类似的手机软件有Anki。（3）要多使用主动记忆（回忆：未见到知识而回忆起知识）而避免被动记忆（再认：见到笔记后再回想起知识）。被动记忆更适合用于设置小测验（根据笔记出题检测自己） 四、计划与整理要形成一个系统：（1）任务管理器：Evernote（2）如何整理笔记。之前的笔记可能比较散乱，要找出时间进行整理，关于知识的整理可以像这样发布在Hexo上。（3）保证笔记都有物理存储方式（每天的笔记很散乱，最好有一个物理载体能把它们归类到一起，比如一个文件盒，我暂时想到的是买散页纸的包装带，或者找文件夹）（4）开发方案，也就是制定计划（我的理解是每天和每周都做总结，就像兼辅考核表一样） 五、注意力与集中（1）注意力随时间递减（2）一般工作25~30分钟，要休息几分钟，但不要做分散注意力的事。（3）注意力与健康有关，养成好习惯（睡眠7hours，每天锻炼）（4）注意力与环境有关，尽量给自己找一个不受干扰的好环境。 六、文章与写作（对应视频第9集）（1）先进行“前写作”（针对已有的结果进行粗糙的写作）（2）带着上一版的问题定向找资源，并记录资源的量，够用就行。（3）开始写作，但不要带有完美主义。（4）修改论文时先看框架，再看语句。改完后可以大声朗读/打印出来进行修改，效果比较好。]]></content>
      <categories>
        <category>技能</category>
      </categories>
      <tags>
        <tag>学习</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[莫烦Numpy和Pandas数据处理教程]]></title>
    <url>%2F2019%2F04%2F02%2F%E8%8E%AB%E7%83%A6Numpy%E5%92%8CPandas%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Numpy一、Numpy的属性12345678import numpy as nparray = np.array([[1,2,3],[2,3,4]])print(array)print(&apos;number of dim:&apos;,array.ndim) #维度print(&apos;shape:&apos;,array.shape) #几行几列print(&apos;size:&apos;,array.size) #几个元素 二、Numpy创建Array五、Numpy的索引1234import numpy as npA = np.arange(3,15)print(A) #[3 4 5 6 7 8 9 10 11 12 13 14]print(A[3]) #6 矩阵换成二维的1234567891011121314151617181920212223import numpy as npA = np.arange(3,15).reshape((3,4))print(A) #[[3 4 5 6] [7 8 9 10] [11 12 13 14]]print(A[2]) #[11 12 13 14]print(A[1][1]) #8 print(A[1,1]) #8 与上述效果一样print(A[:,1]) #第2列的所有数print(A[1,:]) #第2行的所有数print(A[1,1:2]) #[8]print(A[1,1:3]) #[8,9]for row in A: print(row) #按行输出for column in A.T: print(column) #按列输出print(A.flatten()) #把矩阵变成一维for item in A.flat: print(item) #flat和flatten()功能一样，返回值不一样。返回一维矩阵用flatten(),flat是迭代器，返回的是一串类似地址值的值 三、Numpy的Array合并合并12345678910import numpy as npA = np.array([1,1,1])B = np.array([2,2,2])print(np.vstack(A,B)) #vertical stack 上下合并# [1,1,1] [2,2,2]print(np.hstack(A,B)) #horizontal stack 左右合并# [1,1,1,2,2,2] 增加维度123456print(A[:,np.newaxis]) #增加列维度# [[1] [1] [1]]print(A[np.newaxis,:]) #增加行维度# [[1,1,1]] 例子：123456789A = np.array([1,1,1])[:,np.newaxis]B = np.array([2,2,2])[:,np.newaxis]C = np.hstack(A,B)print(C)# [1,2] [1,2] [1,2]print(A.shape,C.shape)# (3,1) (3,2) 多个Array合并123456789101112131415161718C = np.concatenate((A,B,B,A)，axis=0) # vstack和hstack都可以进行多个Array合并，# concatenate的不同在于可以在后面指定合并的方向。# 0为上下合并，1为水平合并print(C)#[[1] [1] [1] [2] [2] [2] [2] [2] [2] [1] [1] [1]] 四、Numpy的分割先生成一个array：12345678910111213141516171819import numpy as npA = np.arange(12).reshape((3,4))print(A)# [[0,1,2][3,4,5][6,7,8][9,10,11]]print(np.split(A,2,axis=1))#1是上下分开，0是左右分开# [array([[0,1], [4,5], [8,9]]), array([[2,3], [6,7], [10,11]])] split只能进行相同分割，进行不相等分割要使用array_split123456789101112print(np.array_split(A,3,axis=1))#[array([[0,1], [4,5], [8,9]]), array([[2], [6], [10]]) array([[3], [7], [11]])] 相对于合并，分割也有vsplit和hsplit123456789101112print(np.vsplit(A,3))#[array([[0,1,2,3]])],[array([[4,5,6,7]])],[array([[8,9,10,11]])]print(np.hsplit(A,2))#[array([[0,1], [4,5], [8,9]]), array([[2,3], [6,7], [10,11]])] 五、Numpy的copy和deep copy12345678910111213141516import numpy as npa = np.arange(4)b = ac = ad = ba[0] = 11 #默认格式是整数# 此时a,b,c,d都会改变，因为python中这种赋值方式下a,b,c,d是完全一样的d[1:3] = [22,33]# 此时a,b.c,d也会全部发生改变b = a.copy() #deep copya[3] = 44#a = [11,22,33,44]b = [11,22,33,3]deep copy后,a变化不会使b变化 Pandas一、Pandas的基本介绍Series123456789101112import pandas as pdimport numpy as nps = pd.Series([1,3,6,np.nan,44,1])print(s)#0 1.01 3.02 6.03 NaN4 44.05 1.0dtype: float64 DataFrame1234567891011121314151617dates = pd.date_range(&apos;20160101&apos;,periods=6)print(dates)# 先生成一个索引DatetimeIndex([&apos;2016-01-01&apos;, &apos;2016-01-02&apos;, &apos;2016-01-03&apos;, &apos;2016-01-04&apos;, &apos;2016-01-05&apos;, &apos;2016-01-06&apos;], dtype=&apos;datetime64[ns]&apos;, freq=&apos;D&apos;)df = pd.DataFrame(np.random.randn(6,4),index=dates,columns=[&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;])print(df)# 生成DataFrame a b c d2016-01-01 0.545643 2.021614 1.210559 0.4678342016-01-02 0.666108 0.419161 -1.943871 -0.9532632016-01-03 -0.759923 -0.337458 -1.865560 0.3280372016-01-04 0.198904 0.880258 -1.369046 0.8859452016-01-05 -0.828801 -0.602095 -0.897741 0.1682772016-01-06 0.937178 -0.593869 0.043363 -0.273371 没有索引生成DataFrame1234567df1 = pd.DataFrame(np.random.randn(3,4))print(df1)# 0 1 2 30 0.378297 -0.354029 0.407989 -0.0678381 -1.210963 2.706774 0.875143 0.3606812 -0.964372 0.919133 0.768482 0.221687 按索引排序123456789df1 = pd.DataFrame(np.arange(12).reshape((3,4)))print(df1)print(df1.sort_index(axis=0,ascending=False)) # 0 1 2 32 8 9 10 111 4 5 6 70 0 1 2 3 按值排序123456print(df1.sort_values(by=2))# 0 1 2 30 0 1 2 31 4 5 6 72 8 9 10 11 二、选择数据先生成一个DataFrame1234567891011121314151617181920212223242526272829303132333435363738394041424344import pandas as pdimport numpy as npdates = pd.date_range(&apos;20130101&apos;,periods=6)df = pd.DataFrame(np.arange(24).reshape((6,4)),index=dates,columns=[&apos;A&apos;,&apos;B&apos;,&apos;C&apos;,&apos;D&apos;])print(df)print(df[&apos;A&apos;])print(df.A)# A B C D2013-01-01 0 1 2 32013-01-02 4 5 6 72013-01-03 8 9 10 112013-01-04 12 13 14 152013-01-05 16 17 18 192013-01-06 20 21 22 232013-01-01 02013-01-02 42013-01-03 82013-01-04 122013-01-05 162013-01-06 20Freq: D, Name: A, dtype: int322013-01-01 02013-01-02 42013-01-03 82013-01-04 122013-01-05 162013-01-06 20Freq: D, Name: A, dtype: int32print(df[0:3])print(df[&apos;20130102&apos;:&apos;20130104&apos;])# A B C D2013-01-01 0 1 2 32013-01-02 4 5 6 72013-01-03 8 9 10 11 A B C D2013-01-02 4 5 6 72013-01-03 8 9 10 112013-01-04 12 13 14 15 从标签来选择1234567print(df.loc[&apos;20130102&apos;])#A 4B 5C 6D 7Name: 2013-01-02 00:00:00, dtype: int32 从列标签中选择，并输出所有行结果1234567891011121314151617print(df.loc[:,[&apos;A&apos;,&apos;B&apos;]])# A B2013-01-01 0 12013-01-02 4 52013-01-03 8 92013-01-04 12 132013-01-05 16 172013-01-06 20 21print(df.loc[&apos;20130102&apos;:,[&apos;A&apos;,&apos;B&apos;]]) A B2013-01-02 4 52013-01-03 8 92013-01-04 12 132013-01-05 16 172013-01-06 20 21 从位置选择123456789101112131415161718192021222324print(df.iloc[3]) #第4行的数据#A 12B 13C 14D 15Name: 2013-01-04 00:00:00, dtype: int32print(df.iloc[3，1]) #第4行第2个数据#13print(df.iloc[3:5，1:3]) #第4行到第6行，第2位到第4位# B C2013-01-04 13 142013-01-05 17 18print(df.iloc[[1,3,5],1:3]) #第2，4，6行...# B C2013-01-02 5 62013-01-04 13 142013-01-06 21 22 混合选择123456print(df.ix[:3,[&apos;A&apos;,&apos;C&apos;]])# A C2013-01-01 0 22013-01-02 4 62013-01-03 8 10 其它1234567891011121314print(df)print(df[df.A&gt;8])# A B C D2013-01-01 0 1 2 32013-01-02 4 5 6 72013-01-03 8 9 10 112013-01-04 12 13 14 152013-01-05 16 17 18 192013-01-06 20 21 22 23 A B C D2013-01-04 12 13 14 152013-01-05 16 17 18 192013-01-06 20 21 22 23 三、Pandas设置值先生成一个DataFrame123456789101112131415161718192021222324252627282930313233343536373839dates = pd.date_range(&apos;20130101&apos;,periods=6)df = pd.DataFrame(np.arange(24).reshape((6,4)),index=dates,columns=[&apos;A&apos;,&apos;B&apos;,&apos;C&apos;,&apos;D&apos;])# A B C D2013-01-01 0 1 2 32013-01-02 4 5 6 72013-01-03 8 9 10 112013-01-04 12 13 14 152013-01-05 16 17 18 192013-01-06 20 21 22 23df.iloc[2,2] = 1111print(df)# A B C D2013-01-01 0 1 2 32013-01-02 4 5 6 72013-01-03 8 9 10 112013-01-04 12 13 14 152013-01-05 16 17 18 192013-01-06 20 21 22 23 A B C D2013-01-01 0 1 2 32013-01-02 4 5 6 72013-01-03 8 9 1111 112013-01-04 12 13 14 152013-01-05 16 17 18 192013-01-06 20 21 22 23df.loc[&apos;20130101&apos;,&apos;A&apos;] = 2222print(df)# A B C D2013-01-01 2222 1 2 32013-01-02 4 5 6 72013-01-03 8 9 1111 112013-01-04 12 13 14 152013-01-05 16 17 18 192013-01-06 20 21 22 23 另一种设置值的方法123456789101112131415161718192021df[df.A&gt;4] = 0print(df)# A B C D2013-01-01 0 1 2 32013-01-02 4 5 6 72013-01-03 0 0 0 02013-01-04 0 0 0 02013-01-05 0 0 0 02013-01-06 0 0 0 0df.A[df.A&gt;4] = 0print(df)# A B C D2013-01-01 0 1 2 32013-01-02 4 5 6 72013-01-03 0 9 10 112013-01-04 0 13 14 152013-01-05 0 17 18 192013-01-06 0 21 22 23 加一列123456789101112131415161718192021df[&apos;F&apos;] = np.nanprint(df)# A B C D F2013-01-01 0 1 2 3 NaN2013-01-02 4 5 6 7 NaN2013-01-03 8 9 10 11 NaN2013-01-04 12 13 14 15 NaN2013-01-05 16 17 18 19 NaN2013-01-06 20 21 22 23 NaNdf[&apos;E&apos;] = pd.Series([1,2,3,4,5,6],index=pd.date_range(&apos;20130101&apos;,periods=6))print(df)# A B C D E2013-01-01 0 1 2 3 12013-01-02 4 5 6 7 22013-01-03 8 9 10 11 32013-01-04 12 13 14 15 42013-01-05 16 17 18 19 52013-01-06 20 21 22 23 6 四、Pandas处理异常数据生成一个带有Nan的DataFrame12345678910111213141516171819202122232425import pandas as pdimport numpy as npdates = pd.date_range(&apos;20130101&apos;,periods=6)df = pd.DataFrame(np.arange(24).reshape((6,4)),index=dates,columns=[&apos;A&apos;,&apos;B&apos;,&apos;C&apos;,&apos;D&apos;])df.iloc[0,1] = np.nandf.iloc[1,2] = np.nanprint(df)# A B C D2013-01-01 0 NaN 2.0 32013-01-02 4 5.0 NaN 72013-01-03 8 9.0 10.0 112013-01-04 12 13.0 14.0 152013-01-05 16 17.0 18.0 192013-01-06 20 21.0 22.0 23print(df.dropna(axis=0,how=&apos;any&apos;))# A B C D2013-01-03 8 9.0 10.0 112013-01-04 12 13.0 14.0 152013-01-05 16 17.0 18.0 192013-01-06 20 21.0 22.0 23 丢掉带有数据的行或列12345678910111213141516171819print(df.dropna(axis=0,how=&apos;any&apos;)) #丢掉行# A B C D2013-01-03 8 9.0 10.0 112013-01-04 12 13.0 14.0 152013-01-05 16 17.0 18.0 192013-01-06 20 21.0 22.0 23print(df.dropna(axis=1,how=&apos;any&apos;)) #丢掉列# A D2013-01-01 0 32013-01-02 4 72013-01-03 8 112013-01-04 12 152013-01-05 16 192013-01-06 20 23print(df.dropna(axis=0,how=&apos;all&apos;)) #行或列全是Nan才删除 将没有填的空，填上数据123456789print(df.fillna(value=0))# A B C D2013-01-01 0 0.0 2.0 32013-01-02 4 5.0 0.0 72013-01-03 8 9.0 10.0 112013-01-04 12 13.0 14.0 152013-01-05 16 17.0 18.0 192013-01-06 20 21.0 22.0 23 判断整个表格中数据是否存在123456789print(df.isnull())# A B C D2013-01-01 False True False False2013-01-02 False False True False2013-01-03 False False False False2013-01-04 False False False False2013-01-05 False False False False2013-01-06 False False False False 数据太多，没办法每行每列找，可以用下列方法123print(np.any(pd.isnull()) == True)#True 五、Pandas导入导出导入表格12345678910111213141516import pandas as pdimport numpy as npdata = pd.read_csv(&apos;C:/Users/zz/Desktop/Python training/1.csv&apos;)print(data)# Student ID Name Gender Language0 1 A male C1 2 B female E2 3 C male A3 4 D female C4 5 E male E5 6 F male A6 7 G female A7 8 H female E8 9 I female C 导出表格1data.to_pickle(&apos;2.pickle&apos;) 六、Pandas合并 concate生成三个DataFrame12345678910111213141516171819202122import pandas as pdimport numpy as npdf1 =pd.DataFrame(np.ones((3,4))*0,columns=[&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;])df2 =pd.DataFrame(np.ones((3,4))*1,columns=[&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;])df3 =pd.DataFrame(np.ones((3,4))*2,columns=[&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;])print(df1)print(df2)print(df3)# a b c d0 0.0 0.0 0.0 0.01 0.0 0.0 0.0 0.02 0.0 0.0 0.0 0.0 a b c d0 1.0 1.0 1.0 1.01 1.0 1.0 1.0 1.02 1.0 1.0 1.0 1.0 a b c d0 2.0 2.0 2.0 2.01 2.0 2.0 2.0 2.02 2.0 2.0 2.0 2.0 第一种合并123456789101112131415161718192021res = pd.concat([df1,df2,df3],axis=0)print(res)# a b c d0 0.0 0.0 0.0 0.01 0.0 0.0 0.0 0.02 0.0 0.0 0.0 0.00 1.0 1.0 1.0 1.01 1.0 1.0 1.0 1.02 1.0 1.0 1.0 1.00 2.0 2.0 2.0 2.01 2.0 2.0 2.0 2.02 2.0 2.0 2.0 2.0res = pd.concat([df1,df2,df3],axis=1)print(res)# a b c d a b c d a b c d0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 2.0 2.0 2.0 2.01 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 2.0 2.0 2.0 2.02 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 2.0 2.0 2.0 2.0 重新赋予左边的索引12345678910111213res = pd.concat([df1,df2,df3],axis=0，ignore_index=True)print(res)# a b c d0 0.0 0.0 0.0 0.01 0.0 0.0 0.0 0.02 0.0 0.0 0.0 0.03 1.0 1.0 1.0 1.04 1.0 1.0 1.0 1.05 1.0 1.0 1.0 1.06 2.0 2.0 2.0 2.07 2.0 2.0 2.0 2.08 2.0 2.0 2.0 2.0 另一种合并(‘outer’,’inner’)先生成两个DataFrame12345678910111213df1 = pd.DataFrame(np.ones((3,4))*0,index=[1,2,3],columns=[&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;])df2 = pd.DataFrame(np.ones((3,4))*1,index=[2,3,4],columns=[&apos;b&apos;,&apos;c&apos;,&apos;d&apos;,&apos;e&apos;])print(df1)print(df2)# a b c d1 0.0 0.0 0.0 0.02 0.0 0.0 0.0 0.03 0.0 0.0 0.0 0.0 b c d e2 1.0 1.0 1.0 1.03 1.0 1.0 1.0 1.04 1.0 1.0 1.0 1.0 内外连接（默认为outer）1234567891011121314151617181920212223242526272829303132res = pd.concat([df1,df2],join=&apos;outer&apos;)print(res)# a b c d e1 0.0 0.0 0.0 0.0 NaN2 0.0 0.0 0.0 0.0 NaN3 0.0 0.0 0.0 0.0 NaN2 NaN 1.0 1.0 1.0 1.03 NaN 1.0 1.0 1.0 1.04 NaN 1.0 1.0 1.0 1.0res = pd.concat([df1,df2],join=&apos;inner&apos;)print(res)# b c d1 0.0 0.0 0.02 0.0 0.0 0.03 0.0 0.0 0.02 1.0 1.0 1.03 1.0 1.0 1.04 1.0 1.0 1.0res = pd.concat([df1,df2],join=&apos;inner&apos;,ignore_index=True)print(res)# b c d0 0.0 0.0 0.01 0.0 0.0 0.02 0.0 0.0 0.03 1.0 1.0 1.04 1.0 1.0 1.05 1.0 1.0 1.0 根据索引连接123456789df1 = pd.DataFrame(np.ones((3,4))*0,index=[1,2,3],columns=[&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;])df2 = pd.DataFrame(np.ones((3,4))*1,index=[2,3,4],columns=[&apos;b&apos;,&apos;c&apos;,&apos;d&apos;,&apos;e&apos;])res = pd.concat([df1,df2],axis=1,join_axes=[df1.index])print(res)# a b c d b c d e1 0.0 0.0 0.0 0.0 NaN NaN NaN NaN2 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.03 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 append添加123456789101112131415161718192021222324252627df1 =pd.DataFrame(np.ones((3,4))*0,columns=[&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;])df2 =pd.DataFrame(np.ones((3,4))*1,columns=[&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;])df3 =pd.DataFrame(np.ones((3,4))*2,columns=[&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;])res = df1.append(df2,ignore_index=True)print(res)# a b c d0 0.0 0.0 0.0 0.01 0.0 0.0 0.0 0.02 0.0 0.0 0.0 0.03 1.0 1.0 1.0 1.04 1.0 1.0 1.0 1.05 1.0 1.0 1.0 1.0res = df1.append([df2,df3],ignore_index=True)print(res)# a b c d0 0.0 0.0 0.0 0.01 0.0 0.0 0.0 0.02 0.0 0.0 0.0 0.03 1.0 1.0 1.0 1.04 1.0 1.0 1.0 1.05 1.0 1.0 1.0 1.06 2.0 2.0 2.0 2.07 2.0 2.0 2.0 2.08 2.0 2.0 2.0 2.0 七、Pandas合并 merge生成两个DataFrame12345678910111213141516171819202122import pandas as pdimport numpy as npleft = pd.DataFrame(&#123;&apos;key&apos;: [&apos;K0&apos;, &apos;K1&apos;, &apos;K2&apos;, &apos;K3&apos;], &apos;A&apos;: [&apos;A0&apos;, &apos;A1&apos;, &apos;A2&apos;, &apos;A3&apos;], &apos;B&apos;: [&apos;B0&apos;, &apos;B1&apos;, &apos;B2&apos;, &apos;B3&apos;]&#125;)right = pd.DataFrame(&#123;&apos;key&apos;: [&apos;K0&apos;, &apos;K1&apos;, &apos;K2&apos;, &apos;K3&apos;], &apos;C&apos;: [&apos;C0&apos;, &apos;C1&apos;, &apos;C2&apos;, &apos;C3&apos;], &apos;D&apos;: [&apos;D0&apos;, &apos;D1&apos;, &apos;D2&apos;, &apos;D3&apos;]&#125;)print(left)print(right)# key A B0 K0 A0 B01 K1 A1 B12 K2 A2 B23 K3 A3 B3 key C D0 K0 C0 D01 K1 C1 D12 K2 C2 D23 K3 C3 D3 merge12345678res = pd.merge(left,right,on=&apos;key&apos;)print(res)# key A B C D0 K0 A0 B0 C0 D01 K1 A1 B1 C1 D12 K2 A2 B2 C2 D23 K3 A3 B3 C3 D3 两列key1234567891011121314151617181920212223242526left = pd.DataFrame(&#123;&apos;key1&apos;: [&apos;K0&apos;, &apos;K0&apos;, &apos;K1&apos;, &apos;K2&apos;], &apos;key2&apos;: [&apos;K0&apos;, &apos;K1&apos;, &apos;K0&apos;, &apos;K1&apos;], &apos;A&apos;: [&apos;A0&apos;, &apos;A1&apos;, &apos;A2&apos;, &apos;A3&apos;], &apos;B&apos;: [&apos;B0&apos;, &apos;B1&apos;, &apos;B2&apos;, &apos;B3&apos;]&#125;)right = pd.DataFrame(&#123;&apos;key1&apos;: [&apos;K0&apos;, &apos;K1&apos;, &apos;K1&apos;, &apos;K2&apos;], &apos;key2&apos;: [&apos;K0&apos;, &apos;K0&apos;, &apos;K0&apos;, &apos;K0&apos;], &apos;C&apos;: [&apos;C0&apos;, &apos;C1&apos;, &apos;C2&apos;, &apos;C3&apos;], &apos;D&apos;: [&apos;D0&apos;, &apos;D1&apos;, &apos;D2&apos;, &apos;D3&apos;]&#125;)res = pd.merge(left,right,on=[&apos;key1&apos;,&apos;key2&apos;])print(res)# key1 key2 A B C D0 K0 K0 A0 B0 C0 D01 K1 K0 A2 B2 C1 D12 K1 K0 A2 B2 C2 D2res = pd.merge(left,right,on=[&apos;key1&apos;,&apos;key2&apos;],how=&apos;outer&apos;)# how = [&apos;left&apos;,&apos;right&apos;,&apos;outer&apos;,&apos;inner&apos;] print(res)# key1 key2 A B C D0 K0 K0 A0 B0 C0 D01 K0 K1 A1 B1 NaN NaN2 K1 K0 A2 B2 C1 D13 K1 K0 A2 B2 C2 D24 K2 K1 A3 B3 NaN NaN5 K2 K0 NaN NaN C3 D3 indicator生成DataFrame1234df1 = pd.DataFrame(&#123;&apos;col1&apos;:[0,1], &apos;col_left&apos;:[&apos;a&apos;,&apos;b&apos;]&#125;)df2 = pd.DataFrame(&#123;&apos;col1&apos;:[1,2,2],&apos;col_right&apos;:[2,2,2]&#125;)print(df1)print(df2) 使用indicator12345678res = pd.merge(df1, df2, on=&apos;col1&apos;, how=&apos;outer&apos;, indicator=True)print(res)# col1 col_left col_right _merge0 0 a NaN left_only1 1 b 2.0 both2 2 NaN 2.0 right_only3 2 NaN 2.0 right_only index1234567891011121314left = pd.DataFrame(&#123;&apos;A&apos;: [&apos;A0&apos;, &apos;A1&apos;, &apos;A2&apos;], &apos;B&apos;: [&apos;B0&apos;, &apos;B1&apos;, &apos;B2&apos;]&#125;, index=[&apos;K0&apos;, &apos;K1&apos;, &apos;K2&apos;])right = pd.DataFrame(&#123;&apos;C&apos;: [&apos;C0&apos;, &apos;C2&apos;, &apos;C3&apos;], &apos;D&apos;: [&apos;D0&apos;, &apos;D2&apos;, &apos;D3&apos;]&#125;, index=[&apos;K0&apos;, &apos;K2&apos;, &apos;K3&apos;])res = pd.merge(left, right, left_index=True, right_index=True, how=&apos;outer&apos;)print(res)# A B C DK0 A0 B0 C0 D0K1 A1 B1 NaN NaNK2 A2 B2 C2 D2K3 NaN NaN C3 D3 handle overlapping12345678boys = pd.DataFrame(&#123;&apos;k&apos;: [&apos;K0&apos;, &apos;K1&apos;, &apos;K2&apos;], &apos;age&apos;: [1, 2, 3]&#125;)girls = pd.DataFrame(&#123;&apos;k&apos;: [&apos;K0&apos;, &apos;K0&apos;, &apos;K3&apos;], &apos;age&apos;: [4, 5, 6]&#125;)res = pd.merge(boys, girls, on=&apos;k&apos;, suffixes=[&apos;_boy&apos;, &apos;_girl&apos;], how=&apos;inner&apos;)print(res)# k age_boy age_girl0 K0 1 41 K0 1 5 八、Pandas Plot画图生成Series12345678910111213141516import pandas as pdimport numpy as npimport matplotlib.pyplot as pltdata = pd.Series(np.random.randn(1000), index=np.arange(1000))data = data.cumsum()data.plot()plt.show()data = pd.DataFrame(np.random.randn(1000, 4), index=np.arange(1000), columns=list(&quot;ABCD&quot;))data = data.cumsum()ax = data.plot.scatter(x=&apos;A&apos;, y=&apos;B&apos;, color=&apos;DarkBlue&apos;, label=&quot;Class 1&quot;)data.plot.scatter(x=&apos;A&apos;, y=&apos;C&apos;, color=&apos;LightGreen&apos;, label=&apos;Class 2&apos;, ax=ax)plt.show()]]></content>
      <categories>
        <category>技能</category>
      </categories>
      <tags>
        <tag>numpy</tag>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[莫烦Python基础笔记]]></title>
    <url>%2F2019%2F04%2F01%2F%E8%8E%AB%E7%83%A6Python%E5%9F%BA%E7%A1%80%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[一、安装注意配置环境变量和pipe3的环境变量（新版安装时打勾就可以自动配置） 二、基本使用2.1 print功能2.2 基本数学运算&emsp;&emsp;次方用**表示，区别于传统的^.&emsp;&emsp;取余用%2.3 变量variable&emsp;&emsp;命名时多个单词用下划线隔开&emsp;&emsp;多个变量复制：a,b,c = 11,12,13 三、while循环和for循环四、if判断Python中并没有类似三目运算符的命令，但是有替代。如，1234worked = True result = &apos;done&apos; if worked else &apos;not yet&apos;//如果worked是True，则&apos;done&apos;被赋值给result，false则是‘not yet’被赋值给result print(result) 五、定义功能六、变量形式七、模块安装安装Numpy 八、文件读取九、class类十、input输入十一、元组turple、列表List、字典十二、模块import]]></content>
      <categories>
        <category>技能</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F03%2F31%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" $ hexo new ‘My New Post’ More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
